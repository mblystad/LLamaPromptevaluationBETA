# LLamaPromptevaluationBETA
A beta version of an LLM based prompt-technique evaluator:
Python CLI tool for exploring and evaluating prompt engineering techniques using a local LLM via LangChain and Ollama. Designed for students, researchers, and hobbyists who want to **experiment with structured prompting strategies** and see how different chains affect the quality of LLM output.

---

## ðŸ” Features

- Compare outputs from multiple prompting techniques:
  - `basic`
  - `few-shot`
  - `chain-of-thought`
  - `tree-of-thought`
  - `self-consistency`
  - and more...
- Automatically evaluate responses using a local LLM.
- Output includes:
  - Full response set by technique
  - LLM-based qualitative ranking
  - A declared "ðŸ† Best Technique"
  - Readability and consistency metrics
- Modular code structure for easy extension.

---

## âš™ï¸ Requirements

- Python 3.10+
- [Ollama](https://ollama.com) installed and running locally
- A supported local model like `llama3` pulled via Ollama:
```

ollama pull llama3

````

---

## ðŸ“¦ Installation

```bash
git clone https://github.com/yourusername/prompt-engineering-cli.git
cd prompt-engineering-cli
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
````

---

## ðŸš€ Usage

Run the main CLI script:

```bash
python main.py
```

You'll be prompted to enter:

1. The base prompt (e.g., "Give a summary of Crime and Punishment")
2. A role/persona (e.g., "Be a Russian literary critic")
3. A few-shot hint string (e.g., "symbolism: morality: psychology")

All chains will generate responses and write the outputs + evaluation to:

* `evaluation_summary.txt`

---

## ðŸ“ Project Structure

```
.
â”œâ”€â”€ chains.py          # All LangChain prompt chains
â”œâ”€â”€ evaluation.py      # Qualitative + consistency evaluation logic
â”œâ”€â”€ utils.py           # Scoring and formatting utilities
â”œâ”€â”€ main.py            # CLI entry point
â”œâ”€â”€ evaluation_summary.txt  # Output file
â””â”€â”€ README.md
```

---

## âœï¸ Customization

* ðŸ”„ **To add your own technique**, edit `chains.py` and register it in `main.py`.
* ðŸ’¬ **Change the evaluation logic** in `evaluation.py` to use your own rubric.
* ðŸ§ª **Swap the model** via the `Ollama(model="...")` line in `chains.py`.

---

## ðŸ¤ Credits

Created by [Magnus Helgheim Blystad](https://github.com/mblystad)


---

## ðŸ§  Philosophy

> Prompting is not a trick. Itâ€™s a method of thinking.
> This tool helps you **see prompting as reasoning** â€“ with outputs you can measure, test, and refine.

---

## ðŸ“œ License

MIT License

